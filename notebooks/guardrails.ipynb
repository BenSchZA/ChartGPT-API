{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "import os\n",
    "\n",
    "# from chartgpt.agents.agent_toolkits.bigquery.utils import get_tables_summary\n",
    "from app.config.production import datasets\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "import json\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_info(json.loads(os.environ[\"GCP_SERVICE_ACCOUNT\"], strict=False))\n",
    "client = bigquery.Client(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "from app.config import Dataset\n",
    "\n",
    "\n",
    "def get_tables_summary(\n",
    "        client: bigquery.Client,\n",
    "        datasets: List[Dataset],\n",
    "        include_types = False\n",
    ") -> Dict[str, List[Dict[str, List[Union[Tuple[str, str], str]]]]]:\n",
    "    # Generate tables_summary for all tables in datasets\n",
    "    tables_summary = {}\n",
    "    for dataset in datasets:\n",
    "        dataset_id = dataset.id\n",
    "        tables_summary[dataset_id] = {}\n",
    "        for table_id in dataset.tables:\n",
    "            table_ref = client.dataset(dataset_id).table(table_id)\n",
    "            table = client.get_table(table_ref)\n",
    "            tables_summary[dataset_id][table_id] = [\n",
    "                (schema_field.name, schema_field.field_type) if include_types else schema_field.name\n",
    "                for schema_field in table.schema\n",
    "            ]\n",
    "    return tables_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_summary = get_tables_summary(client=client, datasets=datasets, include_types=True)\n",
    "str(tables_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chartgpt.guardrails.applications.text2sql import Text2Sql\n",
    "# from chartgpt.guardrails.validators import BugFreeBigQuerySQL\n",
    "\n",
    "EXAMPLES = \"chartgpt/guardrails/applications/examples.json\"\n",
    "\n",
    "with open(EXAMPLES, \"r\") as f:\n",
    "    examples = json.load(f)\n",
    "\n",
    "app = Text2Sql(\n",
    "    client=client,\n",
    "    sql_schema=str(tables_summary),\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = app(\"What is the average APR for the NFTfi protocol in the past 6 months\")\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.guard.base_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = client.query(query)\n",
    "\n",
    "for row in query_job:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from rich import print\n",
    "from typing import List\n",
    "\n",
    "import guardrails as gd\n",
    "\n",
    "\n",
    "class Analytics(BaseModel):\n",
    "    \"\"\"\n",
    "    Analytics GoogleSQL query and Python code to execute it\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    sql_query: str\n",
    "    python_code: str\n",
    "\n",
    "guard = gd.Guard.from_pydantic(Analytics, prompt=\"What is the average APR for the NFTfi protocol in the past 6 months\")\n",
    "\n",
    "raw_llm_output, validated_output = guard(\n",
    "    openai.ChatCompletion.create,\n",
    "    model=\"gpt-4-0613\",\n",
    "    max_tokens=1024,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_str = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "\n",
    "<output>\n",
    "    <pythoncode\n",
    "        name=\"python_code\"\n",
    "        format=\"bug-free-python\"\n",
    "        on-fail-bug-free-python=\"reask\"\n",
    "    />\n",
    "</output>\n",
    "\n",
    "\n",
    "<prompt>\n",
    "Given a data analysis query, write a short Python code snippet that answers the query using typical Python data analysis libraries.\n",
    "\n",
    "The Python code snippet should return a Pandas DataFrame or show an appropriate Plotly chart.\n",
    "\n",
    "You have access to an authenticated BigQuery client object named `client`.\n",
    "\n",
    "BigQuery Tables Summary:\n",
    "{{tables_summary}}\n",
    "\n",
    "Data Analysis Query:\n",
    "{{data_analysis_query}}\n",
    "\n",
    "@complete_json_suffix</prompt>\n",
    "\n",
    "</rail>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guardrails as gd\n",
    "\n",
    "from rich import print\n",
    "\n",
    "guard = gd.Guard.from_rail_string(rail_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.base_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "data_analysis_query = \"\"\"\n",
    "Create sample data for a Lorenz Attractor system and plot the results.\n",
    "\"\"\"\n",
    "\n",
    "raw_llm_response, validated_response = guard(\n",
    "    openai.Completion.create,\n",
    "    prompt_params={\n",
    "        \"tables_summary\": tables_summary,\n",
    "        \"data_analysis_query\": data_analysis_query\n",
    "    },\n",
    "    engine=\"text-davinci-003\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validated_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validated_response[\"python_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    exec(validated_response[\"python_code\"])\n",
    "    print(\"Success!\")\n",
    "except Exception as e:\n",
    "    print(\"Failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain, OpenAI, SerpAPIWrapper, SQLDatabase, SQLDatabaseChain\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()],)\n",
    "# search = SerpAPIWrapper()\n",
    "# llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "# db = SQLDatabase.from_uri(\"sqlite:///../../../../../notebooks/Chinook.db\")\n",
    "# db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
    "tools = [\n",
    "    # Tool(\n",
    "    #     name = \"Search\",\n",
    "    #     func=search.run,\n",
    "    #     description=\"useful for when you need to answer questions about current events. You should ask targeted questions\"\n",
    "    # ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    ),\n",
    "    # Tool(\n",
    "    #     name=\"FooBar-DB\",\n",
    "    #     func=db_chain.run,\n",
    "    #     description=\"useful for when you need to answer questions about FooBar. Input should be in the form of a question containing full context\"\n",
    "    # )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "\n",
    "from chartgpt.agents.agent_toolkits.bigquery.utils import get_example_query\n",
    "from chartgpt.tools.python.tool import PythonAstREPLTool\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_info(json.loads(os.environ[\"GCP_SERVICE_ACCOUNT\"], strict=False))\n",
    "bigquery_client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "tables_summary = get_tables_summary(client=bigquery_client, datasets=datasets)\n",
    "example_query = get_example_query(datasets=datasets)\n",
    "\n",
    "example_query = get_example_query(datasets=datasets)\n",
    "\n",
    "python_tool_description = inspect.cleandoc(\"\"\"                                           \n",
    "You are a data science and GoogleSQL expert. Answer data and analytics questions or perform exploratory data analysis (EDA) without sharing the data source.\n",
    "\n",
    "When unable to complete an analysis or find an answer, respond with \"Analysis failed: <reason>\".\n",
    "After completing an analysis, respond with \"Analysis complete: <final answer or insight>\".\n",
    "\n",
    "# Tools\n",
    "Utilize ONLY these tools for analysis, following their expected formatting instructions.\n",
    "\n",
    "A Python shell. Use this to execute python commands including: BigQuery queries, Pandas analytics, Plotly charts.\n",
    "Input should be a valid python command.\n",
    "When using this tool, sometimes output is abbreviated -\n",
    "make sure it does not look abbreviated before using it in your answer.\n",
    "                                           \n",
    "# Datasets\n",
    "Access these datasets, tables, and columns:\n",
    "```\n",
    "tables_summary = {tables_summary}\n",
    "```\n",
    "\n",
    "Validate column names using: tables_summary[dataset_id][table_id].\n",
    "\n",
    "# Example SQL Query\n",
    "\n",
    "```\n",
    "{example_query}\n",
    "```\n",
    "\n",
    "# Python Libraries\n",
    "The following Python libraries are available in the environment: [streamlit, plotly, pandas, numpy, sklearn, scipy, statsmodels]\n",
    "\n",
    "The following Python modules have been imported already:\n",
    "```\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "Do not try import or use other libraries.\n",
    "\n",
    "# Instructions\n",
    "- A BigQuery Client in Python, `bigquery_client`, has been initialized and authenticated.\n",
    "- Use the Plotly library for creating charts and plots.\n",
    "- Do NOT make DML statements (INSERT, UPDATE, DELETE, DROP, etc.).\n",
    "- Check column names using: print(tables_summary[dataset_id][table_id])\n",
    "- Always prefer performing complex queries using Pandas rather than SQL.\n",
    "- Unless displaying Plotly charts and Pandas DataFrames, use `print()` to display output, for example on the last line of code.\n",
    "\n",
    "# Data Analysis Guidelines\n",
    "- If asked a geographical question, try use a Plotly map.\n",
    "- Always check what unique values are in a column before querying it e.g. `SELECT DISTINCT column_name FROM table_name`.\n",
    "- When performing EDA, always try check correlation and create statistical plots.\n",
    "\"\"\")\n",
    "                                           \n",
    "python_tool = PythonAstREPLTool(\n",
    "    description=python_tool_description,\n",
    "    locals={\"tables_summary\": tables_summary, \"bigquery_client\": bigquery_client, \"example_query\": example_query},\n",
    ")\n",
    "\n",
    "def query_post_processing(query: str) -> str:\n",
    "    query = query.replace(\"print(\", \"display(\")\n",
    "    imports = inspect.cleandoc(\"\"\"\n",
    "    # Add custom imports and config here for agent\n",
    "    import streamlit as st\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    import pandas as pd\n",
    "\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', 5)\n",
    "\n",
    "    def display(*args):\n",
    "        import streamlit as st\n",
    "        st.write(*args)\n",
    "        return args\n",
    "    \"\"\")\n",
    "    query = imports + \"\\n\" + query\n",
    "    query = re.sub(\".*client =.*\\n?\", \"client = bigquery_client\", query)\n",
    "    query = re.sub(\".*bigquery_client =.*\\n?\", \"\", query)\n",
    "    return query\n",
    "\n",
    "from langchain.tools.human.tool import HumanInputRun\n",
    "\n",
    "python_tool.query_post_processing = query_post_processing\n",
    "tools = [python_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.OPENAI_MULTI_FUNCTIONS,\n",
    "    verbose=True,\n",
    "    max_iterations=5,\n",
    "    early_stopping_method=\"generate\",\n",
    "    streaming=True,\n",
    "    # callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"What is the APR on NFTfi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "def display(*args):\n",
    "    import streamlit as st\n",
    "    st.write(*args)\n",
    "    return args\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create a range of x values\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "\n",
    "# Create a figure\n",
    "fig = go.Figure(\n",
    "    data=[go.Scatter(x=x, y=np.sin(x), mode='lines')],\n",
    "    layout=go.Layout(\n",
    "        title=\"Sine Wave Animation\",\n",
    "        updatemenus=[dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[dict(label=\"Play\",\n",
    "                          method=\"animate\",\n",
    "                          args=[None])])]),\n",
    "    frames=[go.Frame(\n",
    "        data=[go.Scatter(\n",
    "            x=x,\n",
    "            y=np.sin(x + np.pi / 15 * (i % 50)),\n",
    "            mode='lines')]\n",
    "    ) for i in range(100)]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\"\"\"\n",
    "import ast\n",
    "\n",
    "tree = ast.parse(code)\n",
    "module = ast.Module(tree.body[:-1], type_ignores=[])\n",
    "\n",
    "_globals = _locals = {}\n",
    "\n",
    "exec(ast.unparse(module), _globals, _locals)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
